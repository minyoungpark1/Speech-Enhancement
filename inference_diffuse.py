# -*- coding: utf-8 -*-
"""
Created on Sat May  6 00:15:37 2023

@author: robin
"""

# Copyright 2020 LMNT, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import os
import torch
import random
import librosa
import posixpath
import torchaudio
import numpy as np
from glob import glob
from tqdm import tqdm
from pathlib import PureWindowsPath, Path
from collections import OrderedDict

from argparse import ArgumentParser

random.seed(23)

from models.DiffuSE import DiffuSE
from config import get_config
from utils.compute_metrics import compute_metrics


def parse_option():
    parser = ArgumentParser(description='runs inference on a spectrogram file generated by diffwave.preprocess')
    parser.add_argument('--output', '-o', type=str, required=True, 
                        help='output path name')
    parser.add_argument('--model_path', '-m', type=str, required=True, metavar="FILE", 
                        help='path to trained model')
    parser.add_argument('--cfg', type=str, required=True, metavar="FILE", 
                        help='path to config file', )
    parser.add_argument(
        "--opts",
        help="Modify config options by adding 'KEY VALUE' pairs. ",
        default=None,
        nargs='+',
    )
    parser.add_argument('--fast', dest='fast', action='store_true',
    help='fast sampling procedure')
    args, unparsed = parser.parse_known_args()
    
    config = get_config(args)

    return args, config
    

def load_model(args, config, device=torch.device('cuda')):
    model = DiffuSE(
        config.DILATION_CYCLE_LENGTH,
        config.HOP_SAMPLES,
        config.N_SPECS,
        config.NOISE_SCHEDULE,
        config.RESIDUAL_CHANNELS,
        config.RESIDUAL_LAYERS,
        ).to(device)
    
    checkpoint = torch.load(args.model_path, map_location=device)
    state_dict = checkpoint['state_dict']
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        name = k[7:] # remove 'module.'
        new_state_dict[name] = v
    model.load_state_dict(new_state_dict)    
    model.eval()
    
    return model


def inference_schedule(model, config, fast_sampling=False):
    training_noise_schedule = np.array(config.NOISE_SCHEDULE)
    inference_noise_schedule = np.array(model.INFERENCE_NOISE_SCHEDULE) \
        if fast_sampling else training_noise_schedule

    talpha = 1 - training_noise_schedule
    talpha_cum = np.cumprod(talpha)
    beta = inference_noise_schedule
    alpha = 1 - beta
    alpha_cum = np.cumprod(alpha)
    sigmas = [0 for i in alpha]
    for n in range(len(alpha) - 1, -1, -1):
        sigmas[n] = ((1.0 - alpha_cum[n-1]) / (1.0 - alpha_cum[n]) * beta[n])

    T = []
    for s in range(len(inference_noise_schedule)):
        for t in range(len(training_noise_schedule) - 1):
            if talpha_cum[t+1] <= alpha_cum[s] <= talpha_cum[t]:
                twiddle = (talpha_cum[t]**0.5 - alpha_cum[s]**0.5) / \
                    (talpha_cum[t]**0.5 - talpha_cum[t+1]**0.5)
                T.append(t + twiddle)
                break
    T = np.array(T, dtype=np.float32)

    m = [0 for i in alpha]
    gamma = [0 for i in alpha]
    delta = [0 for i in alpha]
    d_x = [0 for i in alpha]
    d_y = [0 for i in alpha]
    delta_cond = [0 for i in alpha]
    delta_bar = [0 for i in alpha]
    c1 = [0 for i in alpha]
    c2 = [0 for i in alpha]
    c3 = [0 for i in alpha]
    oc1 = [0 for i in alpha]
    oc3 = [0 for i in alpha]

    for n in range(len(alpha)):
        m[n] = min(((1- alpha_cum[n])/(alpha_cum[n]**0.5)),1)**0.5
        
    m[-1] = 1

    for n in range(len(alpha)):
        delta[n] = max(1-(1+m[n]**2)*alpha_cum[n],0)
        gamma[n] = sigmas[n]

    for n in range(len(alpha)):
        if n >0:
            d_x[n] = (1-m[n])/(1-m[n-1]) * (alpha[n]**0.5)
            d_y[n] = (m[n]-(1-m[n])/(1-m[n-1])*m[n-1])*(alpha_cum[n]**0.5)
            delta_cond[n] = delta[n] - (((1-m[n])/(1-m[n-1])))**2 * alpha[n] * \
                delta[n-1]
            delta_bar[n] = (delta_cond[n])* delta[n-1]/ delta[n]
        else:
            d_x[n] = (1-m[n])* (alpha[n]**0.5)
            d_y[n]= (m[n])*(alpha_cum[n]**0.5)
            delta_cond[n] = 0
            delta_bar[n] = 0

    for n in range(len(alpha)):
        oc1[n] = 1 / alpha[n]**0.5
        oc3[n] = oc1[n] * beta[n] / (1 - alpha_cum[n])**0.5
        if n >0:
            c1[n] = (1-m[n])/(1-m[n-1])*(delta[n-1]/delta[n])*alpha[n]**0.5 + \
                (1-m[n-1])*(delta_cond[n]/delta[n])/alpha[n]**0.5
            c2[n] = (m[n-1] * delta[n] - (m[n] *(1-m[n]))/(1-m[n-1])*alpha[n]*delta[n-1])*\
                (alpha_cum[n-1]**0.5/delta[n])
            c3[n] = (1-m[n-1])*(delta_cond[n]/delta[n])*(1-alpha_cum[n])**0.5/(alpha[n])**0.5
        else:
            c1[n] = 1 / alpha[n]**0.5
            c3[n] = c1[n] * beta[n] / (1 - alpha_cum[n])**0.5
            
    return alpha, beta, alpha_cum,sigmas, T, c1, c2, c3, delta, delta_bar


@torch.no_grad()
def predict(model, config, spectrogram, noisy_signal, alpha, beta, alpha_cum, 
            sigmas, T, c1, c2, c3, delta, delta_bar, device=torch.device('cuda')):
    # Expand rank 2 tensors by adding a batch dimension.
    if len(spectrogram.shape) == 2:
        spectrogram = spectrogram.unsqueeze(0)
        
    spectrogram = spectrogram.to(device)
    audio = torch.randn(spectrogram.shape[0], 
                        config.HOP_SAMPLES * spectrogram.shape[-1], device=device)
    noise_scale = torch.from_numpy(alpha_cum**0.5).float().unsqueeze(1).to(device)
    noisy_audio = torch.zeros(spectrogram.shape[0], 
                              config.HOP_SAMPLES * spectrogram.shape[-1], device=device)
    noisy_audio[:,:noisy_signal.shape[0]] = torch.from_numpy(noisy_signal).to(device)
    audio = noisy_audio
    gamma = [0.2]
    for n in range(len(alpha) - 1, -1, -1):
        if n > 0:
            predicted_noise =  model(audio, spectrogram, 
                                     torch.tensor([T[n]], device=audio.device)).squeeze(1)
            audio = c1[n] * audio + c2[n] * noisy_audio - c3[n] * predicted_noise
            noise = torch.randn_like(audio)
            newsigma= delta_bar[n]**0.5
            audio += newsigma * noise
        else:
            predicted_noise =  model(audio, spectrogram, 
                                     torch.tensor([T[n]], device=audio.device)).squeeze(1)
            audio = c1[n] * audio - c3[n] * predicted_noise
            audio = (1-gamma[n])*audio+gamma[n]*noisy_audio
            audio = torch.clamp(audio, -1.0, 1.0)
            
    return audio


def main():
    args, config = parse_option()
    
    specnames = []
    npy_paths = [
        os.path.join(config.DATA.NPY_DIR, os.path.basename(config.DATA.TEST_NOISY_DIR))
        ]
    for path in npy_paths:
        specnames += glob(f'{path}/*.wav.spec.npy', recursive=True)

    model = load_model(args, config)
    print(args.fast)
    alpha, beta, alpha_cum, sigmas, T, c1, c2, c3, \
        delta, delta_bar = inference_schedule(model, config, fast_sampling=args.fast)
    
    num = len(specnames)
    metrics_total = np.zeros(6)
    
    for i, spec in tqdm(enumerate(specnames)):
        if isinstance(Path(spec), PureWindowsPath):
            spec = spec.replace(os.sep, posixpath.sep)
        if i == 0:
            output_path = Path(os.path.join(args.output, spec.split("/")[-2]))
            output_path.mkdir(parents=True, exist_ok=True)
        spectrogram = torch.from_numpy(np.load(spec))
        noisy_signal, _ = librosa.load(os.path.join(config.DATA.TEST_NOISY_DIR,
                                                    spec.split("/")[-1].replace(".spec.npy","")),
                                       sr=16000)
        clean_signal, _ = librosa.load(os.path.join(config.DATA.TEST_CLEAN_DIR,
                                                    spec.split("/")[-1].replace(".spec.npy","")),
                                       sr=16000)

        wlen = noisy_signal.shape[0]
        audio = predict(model, config, spectrogram, noisy_signal, alpha, beta, 
                            alpha_cum, sigmas, T,c1, c2, c3, delta, delta_bar)
        audio = audio[:,:wlen]
        metrics = compute_metrics(clean_signal, torch.flatten(audio).cpu().numpy(), 16000, 0)
        metrics = np.array(metrics)
        metrics_total += metrics

        # audio = snr_process(audio,noisy_signal)
        output_name = os.path.join(output_path, spec.split("/")[-1].replace(".spec.npy", ""))
        torchaudio.save(output_name, audio.cpu(), sample_rate=16000)

    metrics_avg = metrics_total / num
    print(f'pesq: {metrics_avg[0]:.3f}\t '\
          f'csig: {metrics_avg[1]:.3f}\t '\
          f'cbak: {metrics_avg[2]:.3f}\t '\
          f'covl: {metrics_avg[3]:.3f}\t '\
          f'ssnr: {metrics_avg[4]:.3f}\t '\
          f'stoi: {metrics_avg[5]:.3f}')

if __name__ == '__main__':
    main()
